{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading dataset from .sqlite file downloaded from https://www.kaggle.com/rtatman/188-million-us-wildfires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = sqlite3.connect('FPA_FOD_20170508.sqlite')\n",
    "query = 'SELECT * FROM Fires'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(query, eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to .csv for easier access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('wildfires.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking column for later dropping. Columns description can be found here: https://www.kaggle.com/rtatman/188-million-us-wildfires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('wildfires.csv', low_memory=False, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'year', 'disc_date', 'disc_doy', 'cause_code', 'cause', 'size',\n",
       "       'size_class', 'lat', 'lon', 'state', 'shape'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping unneeded columns. The following attributes are not related to the location, date or size of the wildfire and therefore are not of interest for my analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['FOD_ID', 'FPA_ID', 'SOURCE_SYSTEM_TYPE', 'SOURCE_SYSTEM', 'NWCG_REPORTING_AGENCY', 'NWCG_REPORTING_UNIT_ID', \n",
    "                   'NWCG_REPORTING_UNIT_NAME', 'SOURCE_REPORTING_UNIT', 'SOURCE_REPORTING_UNIT_NAME',\n",
    "                   'LOCAL_FIRE_REPORT_ID', 'LOCAL_INCIDENT_ID', 'FIRE_CODE', 'FIRE_NAME', 'ICS_209_INCIDENT_NUMBER',\n",
    "                   'ICS_209_NAME', 'MTBS_ID', 'MTBS_FIRE_NAME', 'COMPLEX_NAME', 'FIPS_CODE', 'FIPS_NAME', 'OWNER_CODE',\n",
    "                   'OWNER_DESCR', 'COUNTY', 'Shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'year', 'disc_date', 'disc_doy', 'cause_code', 'cause', 'size',\n",
       "       'size_class', 'lat', 'lon', 'state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming and lowercasing columns for easier reading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'objectid': 'id', 'fire_year': 'year', 'discovery_date': 'disc_date', 'discovery_doy': 'disc_doy',\n",
    "                   'discovery_time': 'disc_time', 'stat_cause_code': 'cause_code', 'stat_cause_descr': 'cause',\n",
    "                   'fire_size': 'size', 'fire_size_class': 'size_class', 'latitude': 'lat', 'longitude': 'lon'},\n",
    "                   inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "year               0\n",
       "disc_date          0\n",
       "disc_doy           0\n",
       "disc_time     882638\n",
       "cause_code         0\n",
       "cause              0\n",
       "cont_date     891531\n",
       "cont_doy      891531\n",
       "cont_time     972553\n",
       "size               0\n",
       "size_class         0\n",
       "lat                0\n",
       "lon                0\n",
       "state              0\n",
       "shape              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost half of the observations are missing the time of discovery and control and the actual control date. Given this kind of scale I will not be basing any of my analysis on the time of day at which the wildfire took place or was controlled, and therefore I can simply drop the disc_time, cont_dat, cont_doy and cont_time columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['disc_time', 'cont_date', 'cont_doy', 'cont_time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "year                   int64\n",
       "disc_date     datetime64[ns]\n",
       "disc_doy               int64\n",
       "cause_code           float64\n",
       "cause                 object\n",
       "size                 float64\n",
       "size_class            object\n",
       "lat                  float64\n",
       "lon                  float64\n",
       "state                 object\n",
       "shape                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disc_date column can be converted to datetime format. Checking current format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2005-02-02\n",
       "Name: disc_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.disc_date.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julian date format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = pd.to_datetime(0, unit='s').to_julian_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.disc_date = pd.to_datetime(df.disc_date - epoch, unit='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cont_date = pd.tallo_datetime(df.cont_date - epoch, unit='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning complete, the final look of the df is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>disc_date</th>\n",
       "      <th>disc_doy</th>\n",
       "      <th>cause_code</th>\n",
       "      <th>cause</th>\n",
       "      <th>size</th>\n",
       "      <th>size_class</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>state</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>2005-02-02</td>\n",
       "      <td>33</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>0.10</td>\n",
       "      <td>A</td>\n",
       "      <td>40.036944</td>\n",
       "      <td>-121.005833</td>\n",
       "      <td>CA</td>\n",
       "      <td>b'\\x00\\x01\\xad\\x10\\x00\\x00\\xe8d\\xc2\\x92_@^\\xc0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004-05-12</td>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>0.25</td>\n",
       "      <td>A</td>\n",
       "      <td>38.933056</td>\n",
       "      <td>-120.404444</td>\n",
       "      <td>CA</td>\n",
       "      <td>b'\\x00\\x01\\xad\\x10\\x00\\x00T\\xb6\\xeej\\xe2\\x19^\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004-05-31</td>\n",
       "      <td>152</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Debris Burning</td>\n",
       "      <td>0.10</td>\n",
       "      <td>A</td>\n",
       "      <td>38.984167</td>\n",
       "      <td>-120.735556</td>\n",
       "      <td>CA</td>\n",
       "      <td>b'\\x00\\x01\\xad\\x10\\x00\\x00\\xd0\\xa5\\xa0W\\x13/^\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004-06-28</td>\n",
       "      <td>180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>0.10</td>\n",
       "      <td>A</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>-119.913333</td>\n",
       "      <td>CA</td>\n",
       "      <td>b'\\x00\\x01\\xad\\x10\\x00\\x00\\x94\\xac\\xa3\\rt\\xfa]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004-06-28</td>\n",
       "      <td>180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>0.10</td>\n",
       "      <td>A</td>\n",
       "      <td>38.559167</td>\n",
       "      <td>-119.933056</td>\n",
       "      <td>CA</td>\n",
       "      <td>b'\\x00\\x01\\xad\\x10\\x00\\x00@\\xe3\\xaa.\\xb7\\xfb]\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  year  disc_date  disc_doy  cause_code           cause  size size_class  \\\n",
       "0   1  2005 2005-02-02        33         9.0   Miscellaneous  0.10          A   \n",
       "1   2  2004 2004-05-12       133         1.0       Lightning  0.25          A   \n",
       "2   3  2004 2004-05-31       152         5.0  Debris Burning  0.10          A   \n",
       "3   4  2004 2004-06-28       180         1.0       Lightning  0.10          A   \n",
       "4   5  2004 2004-06-28       180         1.0       Lightning  0.10          A   \n",
       "\n",
       "         lat         lon state  \\\n",
       "0  40.036944 -121.005833    CA   \n",
       "1  38.933056 -120.404444    CA   \n",
       "2  38.984167 -120.735556    CA   \n",
       "3  38.559167 -119.913333    CA   \n",
       "4  38.559167 -119.933056    CA   \n",
       "\n",
       "                                               shape  \n",
       "0  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xe8d\\xc2\\x92_@^\\xc0...  \n",
       "1  b'\\x00\\x01\\xad\\x10\\x00\\x00T\\xb6\\xeej\\xe2\\x19^\\...  \n",
       "2  b'\\x00\\x01\\xad\\x10\\x00\\x00\\xd0\\xa5\\xa0W\\x13/^\\...  \n",
       "3  b'\\x00\\x01\\xad\\x10\\x00\\x00\\x94\\xac\\xa3\\rt\\xfa]...  \n",
       "4  b'\\x00\\x01\\xad\\x10\\x00\\x00@\\xe3\\xaa.\\xb7\\xfb]\\...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to new .csv for easier access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('wildfires_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the analysis I have found that there are 52 states in the list and not 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('wildfires_clean.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AK',\n",
       " 'AL',\n",
       " 'AR',\n",
       " 'AZ',\n",
       " 'CA',\n",
       " 'CO',\n",
       " 'CT',\n",
       " 'DC',\n",
       " 'DE',\n",
       " 'FL',\n",
       " 'GA',\n",
       " 'HI',\n",
       " 'IA',\n",
       " 'ID',\n",
       " 'IL',\n",
       " 'IN',\n",
       " 'KS',\n",
       " 'KY',\n",
       " 'LA',\n",
       " 'MA',\n",
       " 'MD',\n",
       " 'ME',\n",
       " 'MI',\n",
       " 'MN',\n",
       " 'MO',\n",
       " 'MS',\n",
       " 'MT',\n",
       " 'NC',\n",
       " 'ND',\n",
       " 'NE',\n",
       " 'NH',\n",
       " 'NJ',\n",
       " 'NM',\n",
       " 'NV',\n",
       " 'NY',\n",
       " 'OH',\n",
       " 'OK',\n",
       " 'OR',\n",
       " 'PA',\n",
       " 'PR',\n",
       " 'RI',\n",
       " 'SC',\n",
       " 'SD',\n",
       " 'TN',\n",
       " 'TX',\n",
       " 'UT',\n",
       " 'VA',\n",
       " 'VT',\n",
       " 'WA',\n",
       " 'WI',\n",
       " 'WV',\n",
       " 'WY']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df.state.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 excess states are DC (District of Columbia), which is actually a federal district, and PR (Puerto Rico), which is an unincorporated territory. I will be removing all rows related to the two from the dataframe and saving it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.state != 'DC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.state != 'PR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA', 'NM', 'OR', 'NC', 'WY', 'CO', 'WA', 'MT', 'UT', 'AZ', 'SD',\n",
       "       'AR', 'NV', 'ID', 'MN', 'TX', 'FL', 'SC', 'LA', 'OK', 'KS', 'MO',\n",
       "       'NE', 'MI', 'KY', 'OH', 'IN', 'VA', 'IL', 'TN', 'GA', 'AK', 'ND',\n",
       "       'WV', 'WI', 'AL', 'NH', 'PA', 'MS', 'ME', 'VT', 'NY', 'IA', 'MD',\n",
       "       'CT', 'MA', 'NJ', 'HI', 'DE', 'RI'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.state.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('wildfires_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
